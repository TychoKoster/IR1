{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theoretical part:\n",
    "    \n",
    "### 1. Hypothesis Testing\n",
    "\n",
    "##### (a) P(mth experiment gives significant result | m experiments lacking power to reject H0)? <br>\n",
    "\n",
    "The test's probability of making a type 1 error is $\\alpha$ and increases when experiments are repeated.\n",
    "The first m-1 experiments will have to return an insignificant result, which means they don't have the power to reject the null hypothesis. This would be $(1 - \\alpha)$. The probability that the first m-1 experiments gives this result is thus $(1 - \\alpha)^{m-1}$. The $m^{th}$ should be a type 1 error. The total probability is therefore $\\alpha * (1 - \\alpha)^{m-1}$\n",
    "\n",
    "##### (b) P(at least one significant result | m experiments lacking power to reject H0)? <br>\n",
    "\n",
    "Instead of looking at the probability of significant results, we can look at the complement of insignificant results, which leads to an easier computation. The probability that all of the experiments are insignificant is $(1 - \\alpha)^m$. The probability that at least one is then significant is $1 - (1 - \\alpha)^m$ <br>\n",
    "\n",
    "(The family-wise error rate can then be used for the probability of making one or type 1 errors when performing multiple hypothesis tests. Many procedures to control the familywise error rate exist for this, one we could easily use is the Šidák procedure which tests the hypothesis using the formula $1 - (1 - \\alpha)^\\frac{1}{m}$. When the $p_i$ is lower or equal to this measure it rejects the null hypothesis.)\n",
    "\n",
    "### 2. Bias and unfairness in Interleaving experiments\n",
    "\n",
    "In a situation where we have two lists of documents: $l_1$ with documents $d_1$, $d_2$ and $d_3$ and $l_2$ with documents $d_2$, $d_3$ and $d_4$, both ranked in that order. When only document 3 is relevant, $l_2$ should win every time, since it has a higher ranking. However, with Team Draft interleaving, this does not happen, because the merging to the interleaved happens with coin flips and documents will be skipped when they have already been supplied by another list. When document 3 is the only relevant document, what happens in this situation is that after the skipping, both lists now have document 3 as their next document in the list, which means the coin flip doesn't matter and both lists will have the same relevance, as document 3 is the only relevant document, even though one of the lists is clearly better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import pprint\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This block creates all the permutation pairs of P and E\n",
    "\n",
    "relevance = ['N', 'R', 'HR']\n",
    "\n",
    "pairs = []\n",
    "\n",
    "# All permutations of graded relevances of length 5\n",
    "permutations = list(itertools.product(relevance, repeat=5))\n",
    "\n",
    "# All possible pairs of P and E assuming they can give the same outcome\n",
    "for perm in permutations:\n",
    "    for perm_2 in permutations:\n",
    "        pairs.append([perm, perm_2])\n",
    "        \n",
    "# Show 5000 random pairs uniformly selected\n",
    "indices = np.random.randint(0, len(pairs), 5000)\n",
    "sample_pairs = [pairs[i] for i in indices]\n",
    "pp.pprint(sample_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 & Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This block calculates the precision at ranking k of pair P and E and delta measure between the two\n",
    "\n",
    "# Calculates the precision of a ranking\n",
    "def precision_at_k(ranking_pair, k):\n",
    "    precision = 0 \n",
    "    # Prevent k from being out of total amount of docs in ranking\n",
    "    if k > len(ranking_pair):\n",
    "        k = len(ranking_pair)\n",
    "    for i in range(k):\n",
    "        if not ranking_pair[i] == 'N':\n",
    "            precision += 1\n",
    "            \n",
    "    return precision / k\n",
    "\n",
    "k = 10\n",
    "\n",
    "precision_p = precision_at_k(pairs[1000][0], k) \n",
    "precision_e = precision_at_k(pairs[1000][1], k)\n",
    "\n",
    "print(pairs[1000])\n",
    "\n",
    "print(\"Precision of P: {0}\".format(precision_p))\n",
    "print(\"Precision of E: {0}\".format(precision_e))\n",
    "\n",
    "# Show delta measure of a pair with k = 10\n",
    "delta_measure_precision = precision_e - precision_p\n",
    "print(\"Delta measure of precision: {0}\".format(delta_measure_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This block calculates the Normalized Discounted Cumulative Gain (nDCG) at rank k of pair P and E\n",
    "## and the delta measure between the two\n",
    "\n",
    "# Convert relevance to integers, the higher the more relevant\n",
    "graded_relevance = {'N': 0, 'R': 1, 'HR': 2}\n",
    "\n",
    "# Normalized Discounted Cumulative Gain at rank k\n",
    "def nDCG_at_k(ranking_pair, k, highest_rel):\n",
    "    nDCG = 0\n",
    "    best_nDCG = 0\n",
    "    if k > len(ranking_pair):\n",
    "        k = len(ranking_pair)\n",
    "    for i in range(1, k+1):\n",
    "        # Retrieve relevance\n",
    "        rel = graded_relevance[ranking_pair[i-1]]\n",
    "        # Calculate nCDG\n",
    "        nDCG += (2**rel - 1)/(math.log2(1 + i))\n",
    "        \n",
    "        # Assuming ideal is [\"HR\", \"HR\", \"HR\", \"HR\", \"HR\"]\n",
    "        best_nDCG += (2**highest_rel - 1) / (math.log2(1 + i))\n",
    "        \n",
    "    # Return normalized nDCG\n",
    "    return  nDCG / best_nDCG\n",
    "\n",
    "nDCG_p = nDCG_at_k(pairs[1000][0], k, graded_relevance['HR'])\n",
    "nDCG_e = nDCG_at_k(pairs[1000][1], k, graded_relevance['HR'])\n",
    "print(\"P and E pair:\")\n",
    "print(pairs[1000])\n",
    "print(\"\")\n",
    "print(\"nDCG of P: {0}\".format(nDCG_p))\n",
    "print(\"nDCG of E: {0}\".format(nDCG_e))\n",
    "delta_measure_nCDG = nDCG_e - nDCG_p\n",
    "print(\"Delta measure of nCDG: {0}\".format(delta_measure_nCDG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This block converts the relevance [N, R, HR] to probabilities [0, 0.25, 0.75]\n",
    "## It also calculates the Expected Reciprocal Rank of the pair P and E and the delta measure between the two\n",
    "\n",
    "# Based on ERR paper\n",
    "def relevance_probabilities(graded_relevance):\n",
    "    rel_prob = {}\n",
    "    max_value = max(list(graded_relevance.values()))\n",
    "    for key, value in graded_relevance.items():\n",
    "        rel_prob[key] = ((2**value) - 1) / (2**max_value)\n",
    "    return rel_prob\n",
    "\n",
    "# Expected Reciprocal Rank\n",
    "def ERR(ranking_pair, rel_prob):\n",
    "    sum_r = 0\n",
    "    for r in range(1, len(ranking_pair) + 1):\n",
    "        phi_r = rel_prob[ranking_pair[r-1]]\n",
    "        if r != 1:\n",
    "            prod_i = 1 \n",
    "        else:\n",
    "            prod_i = 0\n",
    "        for i in range(1, r):\n",
    "            phi_i = rel_prob[ranking_pair[i-1]]\n",
    "            prod_i *= (1-phi_i) * phi_r\n",
    "        sum_r += (1/r) * prod_i\n",
    "    return sum_r\n",
    "            \n",
    "\n",
    "rel_prob = relevance_probabilities(graded_relevance)\n",
    "print(\"P and E pair:\")\n",
    "print(pairs[1000])\n",
    "ERR_p = ERR(pairs[1000][0], rel_prob)\n",
    "print(\"ERR of P: {0}\".format(ERR_p))\n",
    "ERR_e = ERR(pairs[1000][1], rel_prob)\n",
    "print(\"ERR of E: {0}\".format(ERR_e))\n",
    "delta_measure_ERR = ERR_e - ERR_p\n",
    "print(\"Delta measure of ERR: {0}\".format(delta_measure_ERR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This block contains the balanced interleaving algorithm and a random example of applying interleaving. \n",
    "\n",
    "# Balanced interleaving algorithm\n",
    "def balanced_interleaving(ranking1, ranking2):\n",
    "    I = []\n",
    "    origin = []\n",
    "    k_a = 1\n",
    "    k_b = 1\n",
    "    # RandBit()\n",
    "    priority = np.random.randint(0, 2)\n",
    "    while(k_a <= len(ranking1) or k_b <= len(ranking2)):\n",
    "        if((k_a < k_b) or ((k_a == k_b) and priority == 1)):\n",
    "            # Assume ranking1 and ranking2 have different documents\n",
    "            I.append(ranking1[k_a - 1])\n",
    "            # Store the origin of the document for credit\n",
    "            origin.append(0)\n",
    "            k_a += 1\n",
    "        else:\n",
    "            I.append(ranking2[k_b - 1])\n",
    "            origin.append(1)\n",
    "            k_b += 1     \n",
    "    return I, origin\n",
    "\n",
    "# random doc ids\n",
    "doc_pairs = [('doc1', 'doc2', 'doc3', 'doc4', 'doc5'), ('doc1', 'doc3', 'doc6', 'doc7', 'doc8')]\n",
    "I = balanced_interleaving(doc_pairs[0], doc_pairs[1])\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This block contains the Random Click model algorithm and a random example of its use.\n",
    "\n",
    "# Random Click Model algorithm\n",
    "def random_click_model(number_of_clicks, shown_docs):\n",
    "    # Probability of clicking a document\n",
    "    p = number_of_clicks / shown_docs\n",
    "    clicked = []\n",
    "    for i in range(shown_docs):\n",
    "        clicked.append(np.random.choice([0, 1], p=[1-p, p]))\n",
    "    return clicked\n",
    "\n",
    "# 1 means document at index is clicked\n",
    "clicked = random_click_model(2, 5)\n",
    "print(\"Pair:\")\n",
    "print(pairs[100][0])\n",
    "print(\"Clicked indices:\")\n",
    "print(clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This block contains the Position-Based model algorithm with the use of EM. The trained gamma values are also shown.\n",
    "\n",
    "# Position-Based Model training\n",
    "def train_PBM(sessions, urls_per_query, iterations):\n",
    "    url_sessions = retrieve_url_sessions(sessions)\n",
    "    \n",
    "    old_gamma = init_gamma(urls_per_query)\n",
    "    old_alpha = init_alpha(url_sessions, len(sessions))\n",
    "    # Perform EM algorithm every iterations\n",
    "    for i in range(iterations):\n",
    "        alpha = E_step(url_sessions, sessions, old_gamma, old_alpha, urls_per_query)\n",
    "        gamma = M_step(sessions, old_gamma, old_alpha, urls_per_query)\n",
    "        old_alpha = alpha\n",
    "        old_gamma = gamma\n",
    "    return alpha, gamma\n",
    "\n",
    "# Gamma initialization\n",
    "def init_gamma(urls_per_query):\n",
    "    return [0] * urls_per_query\n",
    "\n",
    "# Alpha initialization for all u (url) and q (sessions)\n",
    "def init_alpha(url_sessions, dim):\n",
    "    alpha = {}\n",
    "    for url in url_sessions:\n",
    "        alpha[url] = {}\n",
    "        for session_index in url_sessions[url]:\n",
    "            alpha[url][session_index] = 0\n",
    "    return alpha\n",
    "\n",
    "# E step of the EM algorithm to update alpha\n",
    "def E_step(url_sessions, sessions, gamma, alpha, urls_per_query):\n",
    "    # Sum of E-step formula for PBM\n",
    "    sum_alpha = init_alpha(url_sessions, len(sessions))\n",
    "    for url in url_sessions:\n",
    "        for session_index in url_sessions[url]:\n",
    "            session = sessions[session_index]\n",
    "            urls = session[0][5:]\n",
    "            rank = urls.index(url)\n",
    "            clicked = 0\n",
    "            if len(session) > 1:\n",
    "                for click in session[1:]:\n",
    "                    if click[3] == url:\n",
    "                        clicked = 1\n",
    "            # Formula for E-step added to total sum\n",
    "            sum_alpha[url][session_index] += (1/len(url_sessions[url])) * (clicked + ((1 - clicked) * (((1 - gamma[rank]) * alpha[url][session_index]) / (1 - gamma[rank] * alpha[url][session_index]))))\n",
    "\n",
    "    return sum_alpha\n",
    "\n",
    "# M_step of the EM algorthm to update gamma\n",
    "def M_step(sessions, gamma, alpha, urls_per_query):\n",
    "    sum_gamma = [0] * urls_per_query\n",
    "    for i, session in enumerate(sessions):\n",
    "        session_index = session[0][0]\n",
    "        query = session[0]\n",
    "        urls = query[5:]\n",
    "        clicked_urls = []\n",
    "        # If clicks in sessions, retrieve the urls\n",
    "        if len(session) > 1:\n",
    "            for click in session[1:]:\n",
    "                clicked_urls.append(click[3])\n",
    "        for rank, url in enumerate(urls):\n",
    "            if url in clicked_urls:\n",
    "                clicked = 1\n",
    "            else:\n",
    "                clicked = 0      \n",
    "            # Formula for M-step PBM\n",
    "            sum_gamma[rank] += clicked + ((1 - clicked) * ((1 - alpha[url][i]) * gamma[rank]) / (1 - gamma[rank] * alpha[url][i]))\n",
    "   # Divide by S\n",
    "    new_gamma = [old_gamma/len(sessions) for old_gamma in sum_gamma]\n",
    "    return new_gamma\n",
    "\n",
    "# Store sessions that contain the url in a dictionary {url : [session numbers that contain it]}\n",
    "def retrieve_url_sessions(sessions):\n",
    "    url_sessions = {}\n",
    "    for i, session in enumerate(sessions):\n",
    "        session_index = int(session[0][0])\n",
    "        for url in session[0][5:]:\n",
    "            if url in url_sessions:\n",
    "                current_sessions = url_sessions[url]\n",
    "                current_sessions.append(i)\n",
    "                url_sessions[url] = current_sessions\n",
    "            else:\n",
    "                url_sessions[url] = [i]\n",
    "    return url_sessions\n",
    "\n",
    "# Store data per session, a query with its clicks [[Session, Clicks]]\n",
    "def read_click_log():\n",
    "    with open('YandexRelPredChallenge.txt', 'r') as f:\n",
    "        data = []\n",
    "        i = -1\n",
    "        # Retrieve first 10000 to avoid memory error\n",
    "        while(i < 10000):\n",
    "            row = f.readline().split()\n",
    "            if row[2] == 'Q' or i == -1:\n",
    "                i += 1\n",
    "                data.append([])\n",
    "                data[i].append(row)\n",
    "            elif row[2] == 'C':\n",
    "                data[i].append(row)\n",
    "        return data\n",
    "\n",
    "data = read_click_log()\n",
    "_, gamma = train_PBM(data, 10, 12)\n",
    "print(\"Gamma values:\")\n",
    "print(gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This block contains the simulation of an interleaving experiment with both click models. \n",
    "## The score of E winning is calculated, with the use of click credit. \n",
    "## The click simulation of the PBM model is also present in this block.\n",
    "\n",
    "# Simulate clicks on the interleaving ranking and \n",
    "# check how many times the E ranking won for both the RCM and PBM model\n",
    "def simulate_interleaving(pair, number_of_clicks, gamma, alpha, N):\n",
    "    wins_e_random = 0\n",
    "    wins_e_pbm = 0 \n",
    "    for _ in range(N):\n",
    "        p = pair[0]\n",
    "        e = pair[1]\n",
    "        interleaved, origin = balanced_interleaving(p, e)\n",
    "        clicked_random = random_click_model(number_of_clicks, len(interleaved))\n",
    "        clicked_pbm = click_pbm(interleaved, gamma, alpha)\n",
    "        score_random = assign_click_credit(origin, clicked_random)\n",
    "        score_pbm = assign_click_credit(origin, clicked_pbm)\n",
    "        # Only wins when score is higher, not equal\n",
    "        if score_random[1] > score_random[0]:\n",
    "            wins_e_random += 1\n",
    "        if score_pbm[1] > score_pbm[0]:\n",
    "            wins_e_pbm += 1     \n",
    "    return wins_e_random, wins_e_pbm\n",
    "\n",
    "# Assign the click credit of an interleaved ranking \n",
    "def assign_click_credit(origin, clicked):\n",
    "    score = [0, 0]\n",
    "    for i, click in enumerate(clicked):\n",
    "        if click == 1:\n",
    "            score[origin[i]] += 1\n",
    "    return score\n",
    "\n",
    "# Simulate clicks using the PBM model\n",
    "def click_pbm(interleaved, gamma, alpha):\n",
    "    clicked = []\n",
    "    for rank, rel in enumerate(interleaved):\n",
    "        prob_click = gamma[rank] * alpha[rel]\n",
    "        clicked.append(np.random.choice([0, 1], p=[1-prob_click, prob_click]))\n",
    "    return clicked\n",
    "\n",
    "N = 100\n",
    "alpha = relevance_probabilities(graded_relevance)\n",
    "wins_random, wins_pbe = simulate_interleaving(pairs[50000], 2, gamma, alpha, N)\n",
    "print(\"E won {0} times out of {1} simulations using random click model\".format(wins_random, N))\n",
    "print(\"E won {0} times out of {1} simulations using pbm model\".format(wins_pbe, N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This block contains the Results of comparison between the offline and online experiments. \n",
    "## It plots the results of the different models and visualizes a comparison between the offline and online experiments.\n",
    "\n",
    "\n",
    "precision_deltas = []\n",
    "win_ratio_randoms = []\n",
    "win_ratio_pbms = []\n",
    "errs = []\n",
    "ndcgs = []\n",
    "k = 10\n",
    "\n",
    "for pair in pairs[:1000]:\n",
    "    # Interleaving simulation for RCM and PBM\n",
    "    win_random, win_pbm = simulate_interleaving(pair, 2, gamma, alpha, N)\n",
    "    P = pair[0]\n",
    "    E = pair[1]\n",
    "    \n",
    "    # Precision P and E\n",
    "    precision_p = precision_at_k(P, k)\n",
    "    precision_e = precision_at_k(E, k)\n",
    "    \n",
    "    # ERR P and E\n",
    "    err_p = ERR(P, rel_prob)\n",
    "    err_e = ERR(E, rel_prob)\n",
    "    \n",
    "    # nDCG P and E\n",
    "    ndcg_p = nDCG_at_k(P, k, graded_relevance['HR'])\n",
    "    ndcg_e = nDCG_at_k(E, k, graded_relevance['HR'])\n",
    "    \n",
    "    # Calculate all delta measures\n",
    "    precision_delta = precision_e - precision_p\n",
    "    err_delta = err_e - err_p\n",
    "    ndcg_delta = ndcg_e - ndcg_p\n",
    "    win_ratio_random = win_random / N\n",
    "    win_ratio_pbm = win_pbm / N\n",
    "    \n",
    "    # Append all values to list for visualization\n",
    "    precision_deltas.append(precision_delta)\n",
    "    errs.append(err_delta)\n",
    "    ndcgs.append(ndcg_delta)\n",
    "    win_ratio_randoms.append(win_ratio_random)\n",
    "    win_ratio_pbms.append(win_ratio_pbm)\n",
    "    \n",
    "# Plot first 250 of precision and clickmodels\n",
    "plt.plot(precision_deltas[:250], label=\"Precision delta's\")\n",
    "plt.plot(win_ratio_randoms[:250], label='Win ratio random')\n",
    "plt.plot(win_ratio_pbms[:250], label='Win ratio pbm')\n",
    "plt.ylabel('Probabilities')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot first 1000 of precision and click models\n",
    "plt.plot(precision_deltas, label=\"Precision delta's\")\n",
    "plt.plot(win_ratio_randoms, label='Win ratio random')\n",
    "plt.plot(win_ratio_pbms, label='Win ratio pbm')\n",
    "plt.ylabel('Probabilities')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot first 250 of ERR and clickmodels\n",
    "plt.plot(errs[:250], label=\"ERR delta's\")\n",
    "plt.plot(win_ratio_randoms[:250], label='Win ratio random')\n",
    "plt.plot(win_ratio_pbms[:250], label='Win ratio pbm')\n",
    "plt.ylabel('Probabilities')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot first 1000 of ERR and click models\n",
    "plt.plot(errs, label=\"ERR delta's\")\n",
    "plt.plot(win_ratio_randoms, label='Win ratio random')\n",
    "plt.plot(win_ratio_pbms, label='Win ratio pbm')\n",
    "plt.ylabel('Probabilities')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot first 250 of nDCG and click models\n",
    "plt.plot(ndcgs[:250], label=\"nDCG delta's\")\n",
    "plt.plot(win_ratio_randoms[:250], label='Win ratio random')\n",
    "plt.plot(win_ratio_pbms[:250], label='Win ratio pbm')\n",
    "plt.ylabel('Probabilities')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot first 1000 of nDCG and click models\n",
    "plt.plot(ndcgs, label=\"nDCG delta's\")\n",
    "plt.plot(win_ratio_randoms, label='Win ratio random')\n",
    "plt.plot(win_ratio_pbms, label='Win ratio pbm')\n",
    "plt.ylabel('Probabilities')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def r(x, y):\n",
    "    return (n * np.sum(x * y) - np.sum(x) * np.sum(y)) \\\n",
    "    / np.sqrt((n * np.sum(x*x) - (np.power(np.sum(x), 2))) \\\n",
    "    * (n * np.sum(y*y) - (np.power(np.sum(y), 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "\n",
    "r1 = r(np.asarray(win_ratio_randoms[:n]), np.asarray(precision_deltas[:n]))\n",
    "r2 = r(np.asarray(win_ratio_randoms[:n]), np.asarray(errs[:n]))\n",
    "r3 = r(np.asarray(win_ratio_randoms[:n]), np.asarray(ndcgs[:n]))\n",
    "r4 = r(np.asarray(win_ratio_pbms[:n]), np.asarray(precision_deltas[:n]))\n",
    "r5 = r(np.asarray(win_ratio_pbms[:n]), np.asarray(errs[:n]))\n",
    "r6 = r(np.asarray(win_ratio_pbms[:n]), np.asarray(ndcgs[:n]))\n",
    "\n",
    "print(\"The Pearson correlation coefficient between the random model and precision delta is: \", r1)\n",
    "print(\"The Pearson correlation coefficient between the random model and ERR is: \", r2)\n",
    "print(\"The Pearson correlation coefficient between the random model and NDCG is: \", r3)\n",
    "print(\"The Pearson correlation coefficient between the PBM and precision delta is: \", r4)\n",
    "print(\"The Pearson correlation coefficient between the PBM and ERR is: \", r5)\n",
    "print(\"The Pearson correlation coefficient between the PBM and NDCG is: \", r6)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A way to look at the correlation between the models and delta measures is using Pearson Correlation Coefficient (PCC). We have shown that in general, these measures highly correlate. The worst correlation was between ERR with the random model. This might be because ERR is an algorithm specifically designed to tackle the downside the assumption made by PCC, which is that is unable to differentiate between dependent and independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Conclusion step 7\n",
    "\n",
    "##### Plot 1 (Precision and Click models)\n",
    "The results of the precision and the PBM Click model seem to loosely correlate with eachother. An explanation for this behavior could be that precision does not incorperate rank when determining the quality of a ranking, while PBM is heavily based on the rank of a document. \n",
    "\n",
    "Another observation seen in the plot is when the precision undergoes a change within ~0.4 the win rate of the PBM model does not change significantly. A possibility for this behavior could be because of the element of randomness that is present in the PBM algorithm. \n",
    "\n",
    "For plot 1 the results of the Random Click model are not relevant.\n",
    "\n",
    "##### Plot 2 (ERR and Click models)\n",
    "The results of the ERR and the PBM correlate more than shown in plot 1. This could be because the ERR model does take position into account, and also models the examination and attractiveness. And because it also models satisfaction it differs slightly from the PBM model. ERR is more of a cascade model, while the PBM model is position based. This would explain the small differences in behavior.\n",
    "\n",
    "For plot 2 the resulls of the Random Click model are not relevant.\n",
    "\n",
    "##### Plot 3 (nDCG and Click models)\n",
    "\n",
    "The results of the nCDG algorithm have a similar pattern as the results of the PBM algorithm. This could be because the nDCG model measures the ranking quality, which means it models the ranking and relevance of a document. It is heavily based on both position and relevance. This is the same for the PBM model, where gamma models the postion and alpha models the relevance. Which would explain the similarity between the two models. \n",
    "\n",
    "##### Interleaving\n",
    "The win ratio of the PBM model could also become higher when the priority of the balanced interleaving algorithm is given to E. This could be an explanation for the spikiness of the plot. This could also be a reason for the differences with the other models. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
